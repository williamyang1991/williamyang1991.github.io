<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>æ¨å¸…</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/misc/yangshuai2.jpg">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%;
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="margin-top: 6px;">
              <img src="images/misc/yangshuai2.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">æ¨  å¸…</h2>
              <p>
                <b>ç‹é€‰è®¡ç®—æœºç ”ç©¶æ‰€</b><br/> 
                åŒ—äº¬å¤§å­¦<br/> 
              </p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/williamyang1991" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:williamyang@pku.edu.cn" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div>
            <!-- slogon -->
          
            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <ul class="menu-list">
                <li><a href="#intro">ä¸ªäººç®€ä»‹</a></li>
                <!--<li><a href="#experiences">å­¦æœ¯ç»å†</a></li>-->
                <li><a href="#project">ç§‘ç ”é¡¹ç›®</a></li>
                <li><a href="#publications">å‘è¡¨æˆæœ</a></li>
                <li><a href="#awards">å¥–é¡¹è£èª‰</a></li>
                <li><a href="#services">å­¦æœ¯æœåŠ¡</a></li>
                <!--<li><a href="#teaching">æ•™å­¦å·¥ä½œ</a></li>-->
              </ul>
              <p style="margin-top: .4em;">
                <a href="https://williamyang1991.github.io/" style="color:#4a4a4a; padding: .5em .75em;"><b>English</b> â¤´ï¸</a>
              </p>
            </div>
          </div>

          

        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="intro">ä¸ªäººç®€ä»‹</h2>
            <p style="text-align: justify;">
              <b>æ¨å¸…</b>, åŒ—äº¬å¤§å­¦ç‹é€‰è®¡ç®—æœºæŠ€æœ¯ç ”ç©¶æ‰€åŠ©ç†æ•™æˆã€åšå¯¼ã€åŒ—äº¬å¤§å­¦åšé›…é’å¹´å­¦è€…ã€æœªåé’å¹´å­¦è€…ã€å›½å®¶çº§é’å¹´äººæ‰è®¡åˆ’è·å¾—è€…. 
              åˆ†åˆ«åœ¨2015å¹´å’Œ2020å¹´è·å¾—åŒ—äº¬å¤§å­¦çš„å­¦å£«å­¦ä½å’Œåšå£«å­¦ä½, 
              2020å¹´è‡³2024å¹´åœ¨æ–°åŠ å¡å—æ´‹ç†å·¥å¤§å­¦å…ˆåä»»åšå£«åå’Œç ”ç©¶åŠ©ç†æ•™æˆ. 
              è·å¾—äº†IEEE ICME 2020çš„æœ€ä½³è®ºæ–‡å¥–å’ŒIEEE MMSP 2015çš„Top10%è®ºæ–‡å¥–. 
              è·å¾—äº†2020å¹´ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼šä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡å¥–å’ŒåŒ—äº¬å¤§å­¦ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡å¥–. 
              æ‹…ä»»ACM MMå’ŒBMVCçš„é¢†åŸŸä¸»å¸­. 
            </p>

            <p>
              ä¸»è¦ç ”ç©¶é¢†åŸŸä¸ºæ™ºèƒ½åª’ä½“è®¡ç®—å’Œè®¡ç®—æœºè§†è§‰, ä¸“æ³¨å›¾åƒé£æ ¼åŒ–å’Œå›¾åƒç¼–è¾‘. 
            </p>
            

            <!--Experience-->
            <h2 id="experiences" style="margin-bottom: 25px;">ç§‘ç ”ç»å†</h2>
            <ul>
              <li>2024.03&nbsp;&nbsp;&nbsp;&nbsp;è‡³&nbsp;&nbsp;&nbsp;ä»Š: <b>åŠ©ç†æ•™æˆ</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@åŒ—äº¬å¤§å­¦</li> 
              <li>2023.03-2024.02: <b>ç ”ç©¶åŠ©ç†æ•™æˆ</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@å—æ´‹ç†å·¥å¤§å­¦</li> 
              <li>2020.10-2023.03: <b>åšå£«å</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@å—æ´‹ç†å·¥å¤§å­¦ | å¯¼å¸ˆ Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a></li>    
              <li>2018.09-2019.09: <b>è®¿é—®å­¦è€…</b> | <a href="https://vita-group.github.io/index.html">VITA</a>@å¾·å·å†œå·¥å¤§å­¦ | å¯¼å¸ˆ Prof. <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang" target="_blank">Atlas Wang</a></li> 
              <li>2017.03-2017.08: <b>è®¿é—®å­¦ç”Ÿ</b> | <a href="https://www.eecs.yorku.ca/~genec/group.html">GSIP</a>@æ—¥æœ¬å›½ç«‹æƒ…æŠ¥å­¦ç ”ç©¶æ‰€ | å¯¼å¸ˆ Prof. <a href="https://www.eecs.yorku.ca/~genec/index.html" target="_blank">Gene Cheung</a></li>                       
              <li>2015.09-2020.07: <b>åšå£«</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@åŒ—äº¬å¤§å­¦ | å¯¼å¸ˆ <a href="https://www.icst.pku.edu.cn/english/people/gg/1297382.htm" target="_blank">éƒ­å®—æ˜</a> ç ”ç©¶å‘˜</li>
              <li>2010.09-2015.07: <b>å­¦å£«</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@åŒ—äº¬å¤§å­¦ | å¯¼å¸ˆ <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html" target="_blank">åˆ˜å®¶ç‘›</a> å‰¯æ•™æˆ</li>         
            </ul>  


            <h2 id="news" style="margin-bottom: 25px;">æœ€æ–°åŠ¨æ€</h2>
            <ul>
              <li>2025.06 ğŸ˜† 3 ç¯‡è®ºæ–‡è¢« ICCV 2025 æ¥æ”¶! </li>
              <li>2025.02 ğŸ˜† 3 ç¯‡è®ºæ–‡è¢« CVPR 2025 æ¥æ”¶! </li>
              <li>2024.07 åŠ å…¥ CSIG ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼š å¤šåª’ä½“ä¸“å§”ä¼š</li> 
              <li>2024.07 å‚åŠ  ICME Workshop on AIArt ä½œ Keynote æŠ¥å‘Š: AIGC for Human Artistic Rendering</li> 
              <li>2024.07 ğŸ˜† 2 ç¯‡è®ºæ–‡è¢« ECCV 2024 æ¥æ”¶! </li>
              <li>2024.05 å‚ä¼š ISCAS ä½œ Tutorial: AIGC for Image and Video Generation</li>  
              <li>2024.03 åŠ å…¥ åŒ—äº¬å¤§å­¦ ç‹é€‰è®¡ç®—æœºæŠ€æœ¯ç ”ç©¶æ‰€ æ‹…ä»»åŠ©ç†æ•™æˆ </li>                       
              <details>
              <summary><li style="margin-top: 5px; margin-bottom: 5px;">å±•å¼€æ›´å¤š</li></summary>
                <li>2024.12 å‚ä¼š æ™ºèƒ½ä¼ åª’æŠ€æœ¯å‘å±•è®ºå› ä½œå­¦æœ¯æŠ¥å‘Š: æ™ºèƒ½è§†è§‰è‰ºæœ¯åˆ›ä½œ</li>
                <li>2024.11 å‚ä¼š é»„å¤§å¹´èŒ¶æ€å±‹ å¤šåª’ä½“é¢†åŸŸé’å¹´å­¦è€…è®ºå› ä½œå­¦æœ¯æŠ¥å‘Š: äººåƒæ™ºèƒ½è‰ºæœ¯æ¸²æŸ“</li>                
                <li>2024.09 æ¬¢è¿å·´è¥¿åœ£ä¿ç½—å¤§å­¦ Roberto M. Cesar-Jr æ•™æˆæ¥è®¿!</li> 
                <li>2024.08 å‚åŠ  APSIPA panel discussion</li>   
                <li>2024.06 å‚åŠ  VALSE Webinar ä½œå­¦æœ¯æŠ¥å‘Š: äººåƒæ™ºèƒ½è‰ºæœ¯è®¾è®¡</li>
                <li>2024.02 ğŸ˜† 2 ç¯‡è®ºæ–‡è¢« CVPR 2024 æ¥æ”¶! </li>
                <li>2023.07 ğŸ˜† 4 ç¯‡è®ºæ–‡è¢« ICCV 2023 æ¥æ”¶! </li>    
                <li>2023.03 æ™‹å‡ å—æ´‹ç†å·¥å¤§å­¦S-Lab ç ”ç©¶åŠ©ç†æ•™æˆ (RAP) </li>
              </details>
            </ul> 

  
            <!--Project-->
            <h2 id="project" style="margin-bottom: 25px;">ç§‘ç ”é¡¹ç›®</h2>
            
            <ul>
              <li>2025-2028, ä¸»æŒ, å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®: è§†è§‰å†…å®¹çš„æ™ºèƒ½å¯æ§ç”Ÿæˆç¼–è¾‘ç ”ç©¶, No.62471009</li> 
              <li>2024-2025, ä¸»æŒ, CCF-è…¾è®¯çŠ€ç‰›é¸Ÿç§‘ç ”åŸºé‡‘é¡¹ç›®: å›¾åƒè§†é¢‘çš„æ™ºèƒ½å¯æ§ç”Ÿæˆä¸ç¼–è¾‘, CCF-Tencent RAGR20240118</li> 
              <li>2025-2027, å‚ä¸, å›½å®¶é‡ç‚¹ç ”å‘è®¡åˆ’: å¤æ‚åŠ¨æ€åœºæ™¯é«˜ä¿çœŸå®æ—¶ä¸‰ç»´é‡å»º, 2024YFB2809101</li> 
              <li>2023-2025, åˆä½œç ”ç©¶å‘˜, å•†æ±¤é«˜æ ¡åˆä½œé¡¹ç›®: Artistic Neural Radiance Fields, HASI-006</li>    
              <li>2021-2023, åˆä½œç ”ç©¶å‘˜, æ–°åŠ å¡æ•™è‚²éƒ¨Tier-1åŸºé‡‘: Human-Centric Visual Manipulation via Interactive Dialog, MoE Tier-1 RG13/21</li>         
            </ul>                                                                                


            <!--Publications-->
            <h2 id="publications">
              å‘è¡¨æˆæœ
            </h2>
            <p>å®Œæ•´åˆ—è¡¨è¯·ç§»æ­¥ <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">Google Scholar</a>; è®ºæ–‡ç›¸å…³èµ„æºè¯·ç§»æ­¥ <a href="https://williamyang1991.github.io/publication.html" target="_blank">Publication</a> </p> 
            <!--List of publications-->
            <b>ç²¾é€‰æœŸåˆŠè®ºæ–‡</b>
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.45, No.10, pp.11869-11993, Oct. 2023.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, and Jiaying Liu. "Shape-Matching GAN++: Scale Controllable Dynamic Artistic Text Style Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.44, No.7, pp.3807-3820, July 2022.</li> 
              <li><b>Shuai Yang</b>â€ , Wenjing Wangâ€ , and Jiaying Liu. "TE141K: Artistic Text Benchmark for Text Effect Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.43, pp.3709-3723, Oct. 2021. (â€ Equal contribution)</li> 
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "VToonify: Controllable High-Resolution Portrait Video Style Transfer", ACM Transactions on Graphics (<b>SIGGRAPH Asia - TOG</b>), Vol.41, No.6, pp.1-15, 2022.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Controllable Sketch-to-Image Translation for Robust Face Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.30, pp.8797-8810, 2021.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Text-Based Binary Image Stylization and Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.952-964, Feb. 2019. </li>
              <li><b>Shuai Yang</b>, Yueyu Hu, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: Scalable Face Image Coding", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.23, pp.2957-2971, Sep. 2021. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Text Effects Transfer via Distribution-Aware Texture Synthesis", Computer Vision and Image Understanding (<b>CVIU</b>), Vol.174, pp.43-56, Sep. 2018.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Yuming Fang, and Zongming Guo. "Joint-Feature Guided Depth Map Super-Resolution with Face Priors", IEEE Transactions on Cybernetics (<b>TCYB</b>), Vol.48, No.1, pp.399-411, Jan. 2018.</li>
              <!--<li>Yuhang Bai, Zichuan Huang, Wenshuo Gao, <b>Shuai Yang</b>*, Jiaying Liu. "Intelligent Artistic Typography: A Comprehensive Review of Artistic Text Design and Generation", APSIPA Transactions on Signal and Information Processing (ATSIP), Vol.13, No.1, pp.1-39, 2024.</li>-->
              <li> Yushi Lan, Xuyi Meng, <b>Shuai Yang</b>, Chen Change Loy, and Bo Dai. "E3DGE: Self-supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion", International Journal of Computer Vision  (<b>IJCV</b>), Jun. 2025.</li>	
              <li>Wendong Mao, <b>Shuai Yang</b>, Huihong Shi, Jiaying Liu, Zhongfeng Wang. "Intelligent Typography: Artistic Text Style Transfer for Complex Texture and Structure", IEEE Transactions on Multimedia (<b>TMM</b>), Vol. 25, pp.6485-6498, Nov. 2023.</li>
              <li>Yuming Jiang, <b>Shuai Yang</b>, Haonan Qiu, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Human: Text-Driven Controllable Human Image Generation", ACM Transactions on Graphics (<b>SIGGRAPH - TOG</b>), Vol.41, No.4, pp.1-11, 2022.</li>
              <li>Xinhao Wang, Wenjing Wang, <b>Shuai Yang</b>, and Jiaying Liu. "CLAST: Contrastive Learning for Arbitrary Style Transfer", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.31, pp.6761-6772, 2022.</li>
              <li>Wenjing Wang, <b>Shuai Yang</b>, Jizheng Xu, and Jiaying Liu. "Consistent Video Style Transfer via Relaxation and Regularization", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.29, pp.8680-8695, 2020.</li>
              <li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Scale-Free Single Image Deraining via Visibility-Enhanced Recurrent Wavelet Learning", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.6, pp.2948-2961, Jun. 2019. </li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, and Zongming Guo. "D3R-Net: Dynamic Routing Residue Recurrent Network for Video Rain Removal", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.699-712, Feb. 2019. </li>
              <!--<li>Xinhao Wang, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Artistic Text Style Transfer", IEEE Signal Processing Magazine (SPM), Vol.39, pp.10-17, Nov. 2022.</li>-->
              <li>Jiaying Liu, <b>Shuai Yang</b>, Yuming Fang, Zongming Guo. "Structure-Guided Image Inpainting Using Homography Transformation", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.20, No.12, pp.3252-3265, Dec. 2018.</li>             
            </ol>
            <b>ç²¾é€‰ä¼šè®®è®ºæ–‡</b>
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation", ACM SIGGRAPH Asia Conference Proceedings (<b>SIGGRAPH Asia</b>), 2023.</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces", International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Unsupervised Image-to-Image Translation with Generative Prior", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches", European Conference on Computer Vision (<b>ECCV</b>), 2020.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Zhaowen Wang, Ning Xu, Jiaying Liu, Zongming Guo. "Controllable Artistic Text Style Transfer via Shape-Matching GAN", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenjing Wang and Zongming Guo. "TET-GAN: Text Effects Transfer via Stylization and Destylization", AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Unsupervised Text Stylization", ACM Multimedia (<b>ACM MM</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Awesome Typography: Statistics-Based Text Effects Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017. </li>
              <!--<li><b>Shuai Yang</b>, Gene Cheung, Jiaying Liu, and Zongming Guo. "Soft Decoding of Light Field Images Using POCS and Fast Graph Spectral Filters", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sifeng Xia, and Zongming Guo. "1+N Fusion: Cascaded Self-Portrait Enhancement", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2017. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sijie Song, Mading Li and Zongming Guo. "Structure-Guided Image Completion via Regularity Statistics", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2016. </li>
              <li><b>Shuai Yang</b>, Sijie Song, Qikun Guo, Xiaoqing Lu and Jiaying Liu. "Facial Depth Map Enhancement via Neighbor Embedding", International Conference on Pattern Recognition (ICPR), 2016. </li>
              <li>Xicheng Lan, Wenshuo Gao, Luyao Zhang, Jiaying Liu, and <b>Shuai Yang</b>*. "Splice, Focus and Relife: High-Resolution Periodic Pattern Generation", IEEE International Symposium on Circuits and Systems (<b>ISCAS</b>), 2025.</li>
              <li>Zichuan Huang, Yifan Li, <b>Shuai Yang</b>*, and Jiaying Liu. "CoolColor: Text-guided COherent OLd film COLORization", ACM Multimedia Asia (ACM MM Asia), 2024.</li>-->
              <li>Wenshuo Gao, Xicheng Lan, and <b>Shuai Yang*</b>. "AnyPortal: Zero-Shot Consistent Video Background Replacement", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Yuxin Jiang, Liming Jiang, <b>Shuai Yang</b>, Jia-Wei Liu, Ivor W. Tsang, and Mike Shou Zheng. "Balanced Image Stylization with Style Matching Score", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Wenqi Ouyang, Zeqi Xiao, Danni Yang, Yifan Zhou, <b>Shuai Yang</b>, Lei Yang, Jianlou Si, and Xingang Pan. "TokensGen: Harnessing Condensed Tokens for Long Video Generation", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Xiang Gao, <b>Shuai Yang</b>, Jiaying Liu. "PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures using Phase-Transferred Diffusion Model", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025.</li>
              <li>Yifan Zhou, Zeqi Xiao, <b>Shuai Yang</b>, Xingang Pan. "Alias-free Latent Diffusion Models: Improving Fractional Shift Equivariance of Diffusion Latent Space", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),2025.</li>
              <li>Yuhan Wang, Fangzhou Hong, <b>Shuai Yang</b>, Liming Jiang, Wayne Wu, Chen Change Loy. "MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025.</li>              
              <li>Zeqi Xiao, Wenqi Ouyang, Yifan Zhou, <b>Shuai Yang</b>, Lei Yang, Jianlou Si, Xingang Pan. "Trajectory Attention for Fine-grained Video Motion Control", International Conference on Learning Representations (<b>ICLR</b>), 2025.</li>
              <li>Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, <b>Shuai Yang</b>, Bo Dai, Xingang Pan, Chen Change Loy. "GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation", International Conference on Learning Representations (<b>ICLR</b>), 2025.</li>
              <li>Zeqi Xiao, Yifan Zhou, <b>Shuai Yang</b>, Xingang Pan. "Video Diffusion Models are Training-free Motion Interpreter and Controller", Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</li>
              <li>Yifan Li, Yuhang Bai, <b>Shuai Yang</b>, and Jiaying Liu. "COCO-LC: Colorfulness Controllable Language-based Colorization", ACM Multimedia (<b>ACM MM</b>), 2024.</li>
              <li>Yushi Lan, Fangzhou Hong, <b>Shuai Yang</b>, Shangchen Zhou, Xuyi Meng, Bo Dai, Xingang Pan, Chen Change Loy. "LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Nanxuan Zhao, Qing Liu, Krishna Kumar Singh, <b>Shuai Yang</b>, Chen Change Loy, Ziwei Liu. "GroupDiff: Diffusion-based Group Portrait Editing", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Tianxing Wu, <b>Shuai Yang</b>, Chenyang Si, Dahua Lin, Yu Qiao, Chen Change Loy, Ziwei Liu. "VideoBooth: Diffusion-based Video Generation with Image Prompts", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li>Yuming Jiang, <b>Shuai Yang</b>, Tong Liang Koh, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Performer: Text-Driven Human Video Generation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yuxin Jiang, Liming Jiang, <b>Shuai Yang</b>, and Chen Change Loy. "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Junzhe Zhang, Yushi Lan, <b>Shuai Yang</b>, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, and Chen Change Loy. "DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yushi Lan, Xuyi Meng, <b>Shuai Yang</b>, Chen Change Loy, and Bo Dai. "E3DGE: Self-supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.</li>
              <li>Hao Liang, <b>Shuai Yang</b>, Wenjing Wang and Jiaying Liu. "Instance-Aware Coherent Video Style Transfer for Chinese Ink Wash Painting", International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2021.</li>
              <li>Qiyu Dai, <b>Shuai Yang</b>, Wenjing Wang, Wei Xiang and Jiaying Liu. "Edit Like A Designer: Modeling Design Workflows for Unaligned Fashion Editing", ACM Multimedia (<b>ACM MM</b>), 2021.</li>
              <li>Yu Han, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "From Design Draft to Real Attire: Unaligned Fashion Image Translation", ACM Multimedia (<b>ACM MM</b>), 2020.</li>
              <li>Yueyu Hu, <b>Shuai Yang</b>, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: A Scalable Image Coding Approach", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020. (<b>Best Paper Award</b>)</li>
              <!--<li>Keqiang Yan, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Multitask Attentive Network for Text Effects Quality Assessment", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020.</li>-->
              <li>Wenjing Wang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Typography with Decor: Intelligent Text Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.</li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, Zongming Guo. "Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018.	</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Sifeng Xia and Zongming Guo. "Hierarchical Oil Painting Stylization with Limited Reference via Sparse Representation", IEEE International Workshop on Multimedia Signal Processing (<b>MMSP</b>), 2015. (<b>Top 10% Paper Awards</b>)</li>
              <!--<li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, Zongming Guo. "Novel Autoregressive Model Based on Adaptive Window-Extension and Patch-Geodesic Distance for Image Interpolation", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2015.</li>
              <li>Saboya Yang, Jiaying Liu, Wenhan Yang and <b>Shuai Yang</b>. "Soft Segmentation-Guided Bipartite Graph Image Stylization ", IEEE International Conference on Image Processing (<b>ICIP</b>), 2017.</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Wenhan Yang and Zongming Guo. "Joint-Domain Unsupervised Stylization for Portraits", IEEE International Symposium on Circuits and Systems (<b>ISCAS</b>), 2017.</li>
              <li>Sifeng Xia, <b>Shuai Yang</b>, Jiaying Liu, and Zongming Guo. "Novel Self-Portrait Enhancement via Multi-Photo Fusing", Asia Pacific Signal and Information Processing Association (APSIPA), 2016.</li>-->              
            </ol>
            <b>ä¹¦ç±æ•™æ</b>:
            <ol class="custom-list">
                <li><b>Shuai Yang</b>, Zhengbo Xu, Wenjing Wang, Jiaying Liu. "Artistic Text Style Transfer". ISBN: 978-1003406273, Artificial Intelligence for Art Creation and Understanding, CRC Press. 2024-08-29</li>
                <li>Ziwei Liu, <b>Shuai Yang</b>, Yuming Jiang, Ziqi Huang. "Generative Networks". ISBN: 978-3-031-43566-9, Handbook of Face Recognition. Springer, Cham. 2023-12-30</li>
                <li>åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, æ¨æ–‡ç€š, æ®µå‡Œå®‡, ã€Šè®¡ç®—æœºè§†è§‰ç†è®ºä¸å®è·µã€‹, ISBN: 9787040574463, 2022-10-01 (â€œæ™ºèƒ½åŸºåº§â€ä¼˜ç§€æ•™æ)</li>              
            </ol>
                     
            <b>æˆæƒä¸“åˆ©</b>:
            <ol class="custom-list">
              <li>åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, æ¨æ–‡ç€š, éƒ­å®—æ˜, ä¸€ç§å›¾æ–‡ç»“åˆçš„æµ·æŠ¥ç”Ÿæˆæ–¹æ³•å’Œç³»ç»Ÿ, ZL201811068309.9, 2023å¹´05æœˆ02æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, èƒ¡ç…œç« , æ±ªæ–‡é–, <b>æ¨å¸…</b>, éƒ­å®—æ˜, ä¸€ç§é’ˆå¯¹ç‰¹æ•ˆå­—çš„æ™ºèƒ½å­—æ•ˆè¿ç§»æ–¹æ³•, ZL201910440039.8, 2022å¹´07æœˆ26æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, èƒ¡è¶Šäºˆ, <b>æ¨å¸…</b>, ç‹å¾·æ˜­, éƒ­å®—æ˜, ä¸€ç§å¯æ‰©å±•äººæœºååŒå›¾åƒç¼–ç æ–¹æ³•åŠç¼–ç ç³»ç»Ÿ, ZL2019114155617, 2022å¹´01æœˆ06æ—¥. </li>
              <li><b>æ¨å¸…</b>, åˆ˜å®¶ç‘›, å®‹æ€æ·, éƒ­å®—æ˜, æ·±åº¦å›¾å¢å¼ºæ–¹æ³•å’Œæ·±åº¦å›¾å¢å¼ºè£…ç½®, ZL201611093936.9, 2021å¹´04æœˆ09æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, æ±ªæ–‡é–, éƒ­å®—æ˜, ä¸€ç§è”åˆé£æ ¼åŒ–å’Œå»é£æ ¼åŒ–çš„è‰ºæœ¯å­—ç¼–è¾‘æ–¹æ³•å’Œç³»ç»Ÿ, ZL201811487971.8, 2021å¹´01æœˆ19æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, æ¨æ–‡ç€š, é­æ™¨, <b>æ¨å¸…</b>, éƒ­å®—æ˜, è§†é¢‘å»é›¨çš„æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠè®¡ç®—æœºå¯è¯»å­˜å‚¨ä»‹è´¨, ZL201810541578.6, 2020å¹´12æœˆ04æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, è¿å®™è¾‰, éƒ­å®—æ˜, ä¸€ç§åŸºäºå¤šé€šé“çš„è‰ºæœ¯å­—ç”Ÿæˆæ–¹æ³•åŠç³»ç»Ÿ, ZL201810078035.5, 2020å¹´11æœˆ03æ—¥. </li>
              <li><b>æ¨å¸…</b>, åˆ˜å®¶ç‘›, å¤æ€çƒ½, éƒ­å®—æ˜, å›¾åƒæ‹¼æ¥æ–¹æ³•åŠè£…ç½®, ZL201710134639.2, 2020å¹´10æœˆ16æ—¥. </li>
              <li><b>æ¨å¸…</b>, å¤æ€çƒ½, åˆ˜å®¶ç‘›, éƒ­å®—æ˜, å¤šå¼ å›¾ç‰‡èåˆçš„æ–¹æ³•åŠè£…ç½®, ZL201710021329.X, 2020å¹´10æœˆ16æ—¥. </li>
              <li>æ¨æ–‡ç€š, åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, éƒ­å®—æ˜, ä¸€ç§åŸºäºç½‘ç»œå›¾åƒå—æ£€ç´¢çš„å›¾åƒé‡å»ºæ–¹æ³•åŠç³»ç»Ÿ, ZL2015100633384.5, 2019å¹´08æœˆ30æ—¥. </li>
              <li>ç™½è”š, åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, éƒ­å®—æ˜, ä¸€ç§å›¾åƒé£æ ¼åŒ–é‡å»ºæ–¹æ³•åŠè£…ç½®, ZL201510379988.1, 2019å¹´05æœˆ07æ—¥. </li>
              <li>æ¨æ’’åšé›…, åˆ˜å®¶ç‘›, <b>æ¨å¸…</b>, éƒ­å®—æ˜, å›¾åƒé£æ ¼åŒ–é‡å»ºçš„æ–¹æ³•å’Œè£…ç½®, ZL201510045335.X, 2019å¹´05æœˆ14æ—¥. </li>
              <li><b>æ¨å¸…</b>, åˆ˜å®¶ç‘›, æé©¬ä¸, æç¿˜æ¥š, éƒ­å®—æ˜, å¤šè¾¹å½¢æ£€æµ‹æ–¹æ³•å’Œå¤šè¾¹å½¢æ£€æµ‹è£…ç½®, ZL201410193194.1, 2019å¹´02æœˆ26æ—¥. </li>
              <li>åˆ˜å®¶ç‘›, æç¿˜æ¥š, æé©¬ä¸, <b>æ¨å¸…</b>, éƒ­å®—æ˜, å›¾åƒå¤„ç†è£…ç½®å’Œå›¾åƒå¤„ç†æ–¹æ³•, ZL 201410200267.5, 2018å¹´04æœˆ17æ—¥. </li>
            </ol> 
            <b>ç”³è¯·ä¸“åˆ©</b>:
            <ol class="custom-list">
              <li><b>æ¨å¸…</b>, å…°æ™°ç¨‹, é«˜æ–‡ç¡•, å¼ ç’ç‘¶, åˆ˜å®¶ç‘›, ä¸€ç§å…·æœ‰å‘¨æœŸæ€§çš„æ¸…æ™°å›¾åƒç”Ÿæˆæ–¹æ³•, 202411823199.8, 2024å¹´12æœˆ11æ—¥.</li>
              <li><b>æ¨å¸…</b>, é«˜æ–‡ç¡•, å…°æ™°ç¨‹, å¼ ç’ç‘¶, åŸºäºéšå¼ç¥ç»è¡¨ç¤ºå’Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„çŸ¢é‡å›¾å½¢åŠ¨ç”»ç”Ÿæˆæ–¹æ³•åŠç³»ç»Ÿ, 202411799939.9, 2024å¹´12æœˆ09æ—¥.</li> 
              <li>åˆ˜å®¶ç‘›, æä¸€å‡¡, <b>æ¨å¸…</b>, ä¸€ç§é¢œè‰²å¯æ§çš„æ–‡æœ¬å¼•å¯¼ç°è‰²å›¾ç€è‰²æ–¹æ³•åŠç³»ç»Ÿ, 2024107362011, 2024å¹´06æœˆ07æ—¥.</li>
              <li>å§œç‘œé“­, <b>æ¨å¸…</b>ï¼Œè®¸ç»Ÿé‡ï¼Œå´æ–‡å²©ï¼Œå•å¥å‹¤ï¼Œåˆ˜å­çº¬ï¼Œè§†é¢‘ç”ŸæˆåŠæ¨¡å‹è®­ç»ƒæ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡ã€å­˜å‚¨ä»‹è´¨, 202311175888.8, 2023å¹´09æœˆ11æ—¥.</li>
              <li><b>æ¨å¸…</b>, è’‹æé¸£, åˆ˜å­çº¬, å•å¥å‹¤, é™¶æ™´æ€¡, å›¾åƒå¤„ç†æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, 202310355783.4, 2023å¹´04æœˆ04æ—¥.</li>
              <li><b>æ¨å¸…</b>, è’‹æé¸£, åˆ˜å­çº¬, å•å¥å‹¤, å¼ ä¿Šå“², æ¨¡å‹è®­ç»ƒåŠå›¾åƒå¤„ç†æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, 202310189704.7, 2023å¹´02æœˆ08æ—¥.</li>           
              <li><b>æ¨å¸…</b>, è’‹æé¸£, åˆ˜å­çº¬, å•å¥å‹¤, é™¶æ™´æ€¡, å›¾åƒå¤„ç†æ–¹æ³•åŠè£…ç½®ã€ç»ˆç«¯ã€å­˜å‚¨ä»‹è´¨, 202210430944.7, 2022å¹´04æœˆ22æ—¥.</li>
              <li><b>æ¨å¸…</b>, è’‹æé¸£, åˆ˜å­çº¬, å•å¥å‹¤, é’±æ™¨, å›¾åƒè½¬æ¢æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, 202210179321.7, 2022å¹´02æœˆ25æ—¥.</li>
              <li>åˆ˜å®¶ç‘›, æ¢æµ©, æ±ªæ–‡é–, <b>æ¨å¸…</b>, éƒ­å®—æ˜, ä¸€ç§åŸºäºå®ä¾‹åˆ†å‰²å’Œå‚è€ƒå¸§çš„æ°´å¢¨è§†é¢‘ç”Ÿæˆæ–¹æ³•åŠè£…ç½®, 202110571615X, 2021å¹´05æœˆ25æ—¥.</li>
              <li>åˆ˜å®¶ç‘›, ç‹æ¬£ç, æ±ªæ–‡é–, <b>æ¨å¸…</b>, éƒ­å®—æ˜, ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„ä»»æ„é£æ ¼è¿ç§»æ–¹æ³•åŠç³»ç»Ÿ, 202110528861.7, 2021å¹´05æœˆ14æ—¥.</li>
            </ol> 

            <!--Awards-->
            <h2 id="awards">å¥–é¡¹è£èª‰</h2>
            <ul>
              <li>2024, ç‹é€‰é’å¹´æ•™å¸ˆå¥–, åŒ—äº¬å¤§å­¦ç‹é€‰è®¡ç®—æœºç ”ç©¶æ‰€</li>
              <li>2024, åŒ—äº¬å¸‚ç§‘å­¦æŠ€æœ¯å‘æ˜å¥– äºŒç­‰å¥–</li> 
              <li>2023, æ°å‡ºå®¡ç¨¿äºº, IEEE/CVF CVPR</li>        
              <li>2022, æ°å‡ºå®¡ç¨¿äºº, ECCV</li>      
              <li>2020, æœ€ä½³è®ºæ–‡å¥–, IEEE ICME</li>         
              <li>2020, ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡å¥–, ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼š</li>
              <li>2020, ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡å¥–, åŒ—äº¬å¤§å­¦</li>
              <li>2019, å­¦æœ¯åæ°, åŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢</li>
              <li>2018, ç½‘ç»œæ–°é’å¹´å½¢è±¡å¤§ä½¿, åŒ—äº¬å¤§å­¦</li>
              <li>2015, åä½³æ¯•ä¸šè®ºæ–‡, åŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢</li>
              <li>2015, Top 10% è®ºæ–‡å¥–, IEEE MMSP</li>
            </ul>

            <h2 id="services">å­¦æœ¯æœåŠ¡</h2>
            <b>å­¦æœ¯æœºæ„ä»»èŒ</b>
            <ul>
              <li>CSIG ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼š, å¤šåª’ä½“ä¸“å§”ä¼šå§”å‘˜</li>
              <li>VALSE è§†è§‰ä¸å­¦ä¹ é’å¹´å­¦è€…ç ”è®¨ä¼š, æ‰§è¡Œé¢†åŸŸä¸»å¸­å§”å‘˜ä¼š EACC</li>
            </ul>            
            <b>é¢†åŸŸä¸»å¸­ AC</b>
            <ul>
              <li>NeurIPS 2025</li>
              <li>ACM MM 2024/2025</li>
              <li>BMVC 2023/2024/2025</li>
            </ul>
              <b>èµ„æ·±ç¨‹åºå§”å‘˜ SPC</b>:
              <ul>
                <li>AAAI 2022/23/24</li>
              </ul>
              <b>ç¨‹åºå§”å‘˜/å®¡ç¨¿äºº PC/Reviwer</b>:
              <ul>
                <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                <li>IEEE Transactions on Visualization and Computer Graphics (TVCG)</li>
                <li>International Journal of Computer Vision (IJCV)</li>
                <li>IEEE Transactions on Image Processing (TIP)</li>
                <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                <li>IEEE Transactions on Multimedia (TMM)</li>
                <li>CVPR 2019/20/21/22/23/24</li>
                <li>ICCV 2019/21/23</li>
                <li>ECCV 2020/22/24</li>
                <li>SIGGRAPH 2022/23/24, SIGGRAPH Asia 2023</li>
                <li>ICLR 2022/23/25</li>
                <li>AAAI 2020/21</li>
                <li>NeurIPS 2022/23</li>               
              </ul>


              <!--Teaching-->
              <h2 id="teaching" style="margin-bottom: 25px;">æ•™å­¦å·¥ä½œ</h2>
              <ul>
                <li>04831300 å›¾åƒå¤„ç† (æœ¬ç§‘ç”Ÿè¯¾ç¨‹) 2024 ç§‹å­£</li> 
                <li>04831750 ç¨‹åºè®¾è®¡å®ä¹  (æœ¬ç§‘ç”Ÿè¯¾ç¨‹) 2025 æ˜¥å­£</li>          
              </ul>  
          </div>
        </div>
      </div>
    </div>



    <!-- Footer -->
    <footer class="container" >
      <br><hr>
      <!--<div class="row" style="text-align: center">
        Â© modified from 2022-2023 Zudi Lin's website
        Zhexin Liang
      </div>-->
     
      <div class="footer_social" style= "text-align: center; margin-left: 275px;">
        <span style="display:inline; font-size: 2em; margin-right: 7px; color: #4a4a4a;">æ¨å¸…</span>
        
        <a href="https://github.com/williamyang1991" target="_blank">
          <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
        </a>
        <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
          <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <a href="mailto:williamyang@pku.edu.cn" target="_blank">
          <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <div class="footer_social" style= "display:inline; float:right;  font-size: 2em;">
          Â© modified from Zudi Lin's website
        </div>
      
 
    </footer>
</section>

  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
