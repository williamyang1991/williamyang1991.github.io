<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>杨帅</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/misc/profile.jpg">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%;
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="margin-top: 6px;">
              <img src="images/misc/yangshuai.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">杨  帅</h2>
              <p>
                <b>王选计算机研究所</b><br/> 
                北京大学<br/> 
              </p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/williamyang1991" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:williamyang@pku.edu.cn" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div>
            <!-- slogon -->
          
            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <ul class="menu-list">
                <li><a href="#intro">个人简介</a></li>
                <li><a href="#experiences">科研经历</a></li>
                <li><a href="#project">科研项目</a></li>
                <li><a href="#publications">发表成果</a></li>
                <li><a href="#awards">奖项荣誉</a></li>
                <li><a href="#services">学术服务</a></li>
                <li><a href="#teaching">教学工作</a></li>
                <li><a href="https://williamyang1991.github.io/">English ⤴️</a></li>
              </ul>
            </div>
          </div>

          

        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="intro">个人简介</h2>
            <p style="text-align: justify;">
              <b>杨帅</b>, 北京大学王选计算机技术研究所助理教授、博导、北京大学未名青年学者、国家级青年人才计划获得者. 
              分别在2015年和2020年获得北京大学的学士学位和博士学位, 
              2020年至2024年在新加坡南洋理工大学先后任博士后和研究助理教授. 
              获得了IEEE ICME 2020的最佳论文奖和IEEE MMSP 2015的Top10%论文奖. 
              获得了2020年中国图象图形学学会优秀博士学位论文奖和北京大学优秀博士学位论文奖. 
              担任ACM MM和BMVC的领域主席. 
            </p>

            <p>
              主要研究领域为智能媒体计算和计算机视觉, 专注图像风格化和图像编辑. 
            </p>
            

            <!--Experience-->
            <h2 id="experiences" style="margin-bottom: 25px;">科研经历</h2>
            
            <article class="columns">

              <div class="column">
                <div class="content">
                  <p>
                    2024.03&nbsp;&nbsp;&nbsp;&nbsp;至&nbsp;&nbsp;&nbsp;今: <b>助理教授</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学                  
                  </p>                  
                  <p>
                    2023.03-2024.02: <b>研究助理教授</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@南洋理工大学                  
                  </p>
                  <p>
                    2020.10-2023.03: <b>博士后</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@南洋理工大学 | 导师 Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a>
                  </p>   
                  <p>
                    2018.09-2019.09: <b>访问学者</b> | <a href="https://vita-group.github.io/index.html">VITA</a>@德州农工大学 | 导师 Prof. <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang" target="_blank">Atlas Wang</a>
                  </p> 
                  <p>
                    2017.03-2017.08: <b>访问学生</b> | <a href="https://www.eecs.yorku.ca/~genec/group.html">GSIP</a>@日本国立情报学研究所 | 导师 Prof. <a href="https://www.eecs.yorku.ca/~genec/index.html" target="_blank">Gene Cheung</a>
                  </p>                       
                  <p>
                    2015.09-2020.07: <b>博士</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学 | 导师 <a href="https://www.icst.pku.edu.cn/english/people/gg/1297382.htm" target="_blank">郭宗明</a> 研究员
                  </p>
                  <p>
                    2010.09-2015.07: <b>学士</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学 | 导师 <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html" target="_blank">刘家瑛</a> 副教授
                  </p>                                                                   
                </div>
              </div>
            </article>

  
            <!--Project-->
            <h2 id="project" style="margin-bottom: 25px;">科研项目</h2>
            
            <ul>
              <li>2025-2027, 主持, 国家自然科学基金面上项目: 视觉内容的智能可控生成编辑研究, No.62471009</li> 
              <li>2024-2025, 主持, CCF-腾讯犀牛鸟科研基金项目: 图像视频的智能可控生成与编辑, CCF-Tencent RAGR20240118</li> 
              <li>2023-2025, 联合主持, 商汤高校合作项目: Artistic Neural Radiance Fields, HASI-006</li>    
              <li>2021-2023, 联合研究员, 新加坡教育部Tier-1基金: Human-Centric Visual Manipulation via Interactive Dialog, MoE Tier-1 RG13/21</li>         
            </ul>                                                                                


            <!--Publications-->
            <h2 id="publications">
              发表成果
            </h2>
            <p>完整列表请移步 <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">Google Scholar</a>; 论文相关资源请移步 <a href="https://williamyang1991.github.io/publication.html" target="_blank">Publication</a> </p> 
            <!--List of publications-->
            <b>精选期刊论文</b>
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.45, No.10, pp.11869-11993, Oct. 2023.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, and Jiaying Liu. "Shape-Matching GAN++: Scale Controllable Dynamic Artistic Text Style Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.44, No.7, pp.3807-3820, July 2022.</li> 
              <li><b>Shuai Yang</b>†, Wenjing Wang†, and Jiaying Liu. "TE141K: Artistic Text Benchmark for Text Effect Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.43, pp.3709-3723, Oct. 2021. (†Equal contribution)</li> 
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "VToonify: Controllable High-Resolution Portrait Video Style Transfer", ACM Transactions on Graphics (<b>SIGGRAPH Asia - TOG</b>), Vol.41, No.6, pp.1-15, 2022.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Controllable Sketch-to-Image Translation for Robust Face Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.30, pp.8797-8810, 2021.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Text-Based Binary Image Stylization and Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.952-964, Feb. 2019. </li>
              <li><b>Shuai Yang</b>, Yueyu Hu, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: Scalable Face Image Coding", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.23, pp.2957-2971, Sep. 2021. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Text Effects Transfer via Distribution-Aware Texture Synthesis", Computer Vision and Image Understanding (<b>CVIU</b>), Vol.174, pp.43-56, Sep. 2018.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Yuming Fang, and Zongming Guo. "Joint-Feature Guided Depth Map Super-Resolution with Face Priors", IEEE Transactions on Cybernetics (<b>TCYB</b>), Vol.48, No.1, pp.399-411, Jan. 2018.</li>
              <!--<li>Yuhang Bai, Zichuan Huang, Wenshuo Gao, <b>Shuai Yang</b>*, Jiaying Liu. "Intelligent Artistic Typography: A Comprehensive Review of Artistic Text Design and Generation", APSIPA Transactions on Signal and Information Processing (ATSIP), Vol.13, No.1, pp.1-39, 2024.</li>-->
              <li>Yuming Jiang, <b>Shuai Yang</b>, Haonan Qiu, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Human: Text-Driven Controllable Human Image Generation", ACM Transactions on Graphics (<b>SIGGRAPH - TOG</b>), Vol.41, No.4, pp.1-11, 2022.</li>
              <li>Xinhao Wang, Wenjing Wang, <b>Shuai Yang</b>, and Jiaying Liu. "CLAST: Contrastive Learning for Arbitrary Style Transfer", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.31, pp.6761-6772, 2022.</li>
              <li>Wenjing Wang, <b>Shuai Yang</b>, Jizheng Xu, and Jiaying Liu. "Consistent Video Style Transfer via Relaxation and Regularization", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.29, pp.8680-8695, 2020.</li>
              <li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Scale-Free Single Image Deraining via Visibility-Enhanced Recurrent Wavelet Learning", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.6, pp.2948-2961, Jun. 2019. </li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, and Zongming Guo. "D3R-Net: Dynamic Routing Residue Recurrent Network for Video Rain Removal", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.699-712, Feb. 2019. </li>
              <!--<li>Xinhao Wang, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Artistic Text Style Transfer", IEEE Signal Processing Magazine (SPM), Vol.39, pp.10-17, Nov. 2022.</li>-->
              <li>Wendong Mao, <b>Shuai Yang</b>, Huihong Shi, Jiaying Liu, Zhongfeng Wang. "Intelligent Typography: Artistic Text Style Transfer for Complex Texture and Structure", IEEE Transactions on Multimedia (<b>TMM</b>), Vol. 25, pp.6485-6498, Nov. 2023.</li>
              <li>Jiaying Liu, <b>Shuai Yang</b>, Yuming Fang, Zongming Guo. "Structure-Guided Image Inpainting Using Homography Transformation", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.20, No.12, pp.3252-3265, Dec. 2018.</li>             
            </ol>
            <b>精选会议论文</b>:
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation", ACM SIGGRAPH Asia Conference Proceedings (<b>SIGGRAPH Asia</b>), 2023.</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces", International Conference on Computer Vision (<b>ICCV</b>), </li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Unsupervised Image-to-Image Translation with Generative Prior", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches", European Conference on Computer Vision (<b>ECCV</b>), 2020.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Zhaowen Wang, Ning Xu, Jiaying Liu, Zongming Guo. "Controllable Artistic Text Style Transfer via Shape-Matching GAN", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenjing Wang and Zongming Guo. "TET-GAN: Text Effects Transfer via Stylization and Destylization", AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Unsupervised Text Stylization", ACM Multimedia (<b>ACM MM</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Awesome Typography: Statistics-Based Text Effects Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017. </li>
              <!--<li><b>Shuai Yang</b>, Gene Cheung, Jiaying Liu, and Zongming Guo. "Soft Decoding of Light Field Images Using POCS and Fast Graph Spectral Filters", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sifeng Xia, and Zongming Guo. "1+N Fusion: Cascaded Self-Portrait Enhancement", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2017. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sijie Song, Mading Li and Zongming Guo. "Structure-Guided Image Completion via Regularity Statistics", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2016. </li>
              <li><b>Shuai Yang</b>, Sijie Song, Qikun Guo, Xiaoqing Lu and Jiaying Liu. "Facial Depth Map Enhancement via Neighbor Embedding", International Conference on Pattern Recognition (ICPR), 2016. </li>
              <li>Zichuan Huang, Yifan Li, <b>Shuai Yang</b>*, and Jiaying Liu. "CoolColor: Text-guided COherent OLd film COLORization", ACM Multimedia Asia (ACM MM Asia), 2024.</li>-->
              <li>Zeqi Xiao, Yifan Zhou, <b>Shuai Yang</b>, Xingang Pan. "Video Diffusion Models are Training-free Motion Interpreter and Controller", Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</li>
              <li>Yifan Li, Yuhang Bai, <b>Shuai Yang</b>, and Jiaying Liu. "COCO-LC: Colorfulness Controllable Language-based Colorization", ACM Multimedia (<b>ACM MM</b>), 2024.</li>
              <li>Yushi Lan, Fangzhou Hong, <b>Shuai Yang</b>, Shangchen Zhou, Xuyi Meng, Bo Dai, Xingang Pan, Chen Change Loy. "LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Nanxuan Zhao, Qing Liu, Krishna Kumar Singh, <b>Shuai Yang</b>, Chen Change Loy, Ziwei Liu. "GroupDiff: Diffusion-based Group Portrait Editing", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Tianxing Wu, <b>Shuai Yang</b>, Chenyang Si, Dahua Lin, Yu Qiao, Chen Change Loy, Ziwei Liu. "VideoBooth: Diffusion-based Video Generation with Image Prompts", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li>Yuming Jiang, <b>Shuai Yang</b>, Tong Liang Koh, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Performer: Text-Driven Human Video Generation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yuxin Jiang, Liming Jiang, <b>Shuai Yang</b>, and Chen Change Loy. "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Junzhe Zhang, Yushi Lan, <b>Shuai Yang</b>, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, and Chen Change Loy. "DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yushi Lan, Xuyi Meng, <b>Shuai Yang</b>, Chen Change Loy, and Bo Dai. "E3DGE: Self-supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.</li>
              <li>Hao Liang, <b>Shuai Yang</b>, Wenjing Wang and Jiaying Liu. "Instance-Aware Coherent Video Style Transfer for Chinese Ink Wash Painting", International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2021.</li>
              <li>Qiyu Dai, <b>Shuai Yang</b>, Wenjing Wang, Wei Xiang and Jiaying Liu. "Edit Like A Designer: Modeling Design Workflows for Unaligned Fashion Editing", ACM Multimedia (<b>ACM MM</b>), 2021.</li>
              <li>Yu Han, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "From Design Draft to Real Attire: Unaligned Fashion Image Translation", ACM Multimedia (<b>ACM MM</b>), 2020.</li>
              <li>Yueyu Hu, <b>Shuai Yang</b>, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: A Scalable Image Coding Approach", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020. (<b>Best Paper Award</b>)</li>
              <!--<li>Keqiang Yan, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Multitask Attentive Network for Text Effects Quality Assessment", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020.</li>-->
              <li>Wenjing Wang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Typography with Decor: Intelligent Text Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.</li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, Zongming Guo. "Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018.	</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Sifeng Xia and Zongming Guo. "Hierarchical Oil Painting Stylization with Limited Reference via Sparse Representation", IEEE International Workshop on Multimedia Signal Processing (<b>MMSP</b>), 2015. (<b>Top 10% Paper Awards</b>)</li>
              <!--<li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, Zongming Guo. "Novel Autoregressive Model Based on Adaptive Window-Extension and Patch-Geodesic Distance for Image Interpolation", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2015.</li>
              <li>Saboya Yang, Jiaying Liu, Wenhan Yang and <b>Shuai Yang</b>. "Soft Segmentation-Guided Bipartite Graph Image Stylization ", IEEE International Conference on Image Processing (<b>ICIP</b>), 2017.</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Wenhan Yang and Zongming Guo. "Joint-Domain Unsupervised Stylization for Portraits", IEEE International Symposium on Circuits and Systems (<b>ISCAS</b>), 2017.</li>
              <li>Sifeng Xia, <b>Shuai Yang</b>, Jiaying Liu, and Zongming Guo. "Novel Self-Portrait Enhancement via Multi-Photo Fusing", Asia Pacific Signal and Information Processing Association (APSIPA), 2016.</li>-->              
            </ol>
            <b>书籍教材</b>:
            <ol class="custom-list">
                <li><b>Shuai Yang</b>, Zhengbo Xu, Wenjing Wang, Jiaying Liu. "Artistic Text Style Transfer". ISBN: 978-1003406273, Artificial Intelligence for Art Creation and Understanding, CRC Press. 2024-08-29</li>
                <li>Ziwei Liu, <b>Shuai Yang</b>, Yuming Jiang, Ziqi Huang. "Generative Networks". ISBN: 978-3-031-43566-9, Handbook of Face Recognition. Springer, Cham. 2023-12-30</li>
                <li>刘家瑛, <b>杨帅</b>, 杨文瀚, 段凌宇, 《计算机视觉理论与实践》, ISBN: 9787040574463, 2022-10-01 (“智能基座”优秀教材)</li>              
            </ol>
                     
            <b>授权专利</b>:
            <ol class="custom-list">
              <li>刘家瑛, <b>杨帅</b>, 杨文瀚, 郭宗明, 一种图文结合的海报生成方法和系统, ZL201811068309.9, 2023年05月02日. </li>
              <li>刘家瑛, 胡煜章, 汪文靖, <b>杨帅</b>, 郭宗明, 一种针对特效字的智能字效迁移方法, ZL201910440039.8, 2022年07月26日. </li>
              <li>刘家瑛, 胡越予, <b>杨帅</b>, 王德昭, 郭宗明, 一种可扩展人机协同图像编码方法及编码系统, ZL2019114155617, 2022年01月06日. </li>
              <li><b>杨帅</b>, 刘家瑛, 宋思捷, 郭宗明, 深度图增强方法和深度图增强装置, ZL201611093936.9, 2021年04月09日. </li>
              <li>刘家瑛, <b>杨帅</b>, 汪文靖, 郭宗明, 一种联合风格化和去风格化的艺术字编辑方法和系统, ZL201811487971.8, 2021年01月19日. </li>
              <li>刘家瑛, 杨文瀚, 魏晨, <b>杨帅</b>, 郭宗明, 视频去雨的方法、装置、设备及计算机可读存储介质, ZL201810541578.6, 2020年12月04日. </li>
              <li>刘家瑛, <b>杨帅</b>, 连宙辉, 郭宗明, 一种基于多通道的艺术字生成方法及系统, ZL201810078035.5, 2020年11月03日. </li>
              <li><b>杨帅</b>, 刘家瑛, 夏思烽, 郭宗明, 图像拼接方法及装置, ZL201710134639.2, 2020年10月16日. </li>
              <li><b>杨帅</b>, 夏思烽, 刘家瑛, 郭宗明, 多张图片融合的方法及装置, ZL201710021329.X, 2020年10月16日. </li>
              <li>杨文瀚, 刘家瑛, <b>杨帅</b>, 郭宗明, 一种基于网络图像块检索的图像重建方法及系统, ZL2015100633384.5, 2019年08月30日. </li>
              <li>白蔚, 刘家瑛, <b>杨帅</b>, 郭宗明, 一种图像风格化重建方法及装置, ZL201510379988.1, 2019年05月07日. </li>
              <li>杨撒博雅, 刘家瑛, <b>杨帅</b>, 郭宗明, 图像风格化重建的方法和装置, ZL201510045335.X, 2019年05月14日. </li>
              <li><b>杨帅</b>, 刘家瑛, 李马丁, 李翘楚, 郭宗明, 多边形检测方法和多边形检测装置, ZL201410193194.1, 2019年02月26日. </li>
              <li>刘家瑛, 李翘楚, 李马丁, <b>杨帅</b>, 郭宗明, 图像处理装置和图像处理方法, ZL 201410200267.5, 2018年04月17日. </li>
            </ol> 
            <b>申请专利</b>:
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, Chen Change Loy. Image processing method and apparatus, device, and storage medium, Singapore Patent Application, 10202250690T</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, Chen Change Loy. Image conversion method and apparatus, device, and storage medium, Singapore Patent Application, 10202110140R</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, Chen Change Loy. Image processing method and apparatus, terminal, and storage medium, Singapore Patent Application, 10202202209R</li>
              <li>刘家瑛, 李一凡, <b>杨帅</b>, 一种颜色可控的文本引导灰色图着色方法及系统, 2024107362011, 2024年06月07日.</li>
              <li>刘家瑛, 梁浩, 汪文靖, <b>杨帅</b>, 郭宗明, 一种基于实例分割和参考帧的水墨视频生成方法及装置, 202110571615X, 2021年05月25日.</li>
              <li>刘家瑛, 王欣灏, 汪文靖, <b>杨帅</b>, 郭宗明, 一种基于对比学习的任意风格迁移方法及系统, 202110528861.7, 2021年05月14日.</li>
            </ol> 

            <!--Awards-->
            <h2 id="awards">奖项荣誉</h2>
            <ul>
              <li>2024, 北京市科学技术发明奖, 二等奖</li> 
              <li>2023, 杰出审稿人, IEEE/CVF CVPR</li>        
              <li>2022, 杰出审稿人, ECCV</li>      
              <li>2020, 最佳论文奖, IEEE ICME</li>         
              <li>2020, 优秀博士学位论文奖, 中国图象图形学学会</li>
              <li>2020, 优秀博士学位论文奖, 北京大学</li>
              <li>2019, 学术十杰, 北京大学信息科学技术学院</li>
              <li>2018, 网络新青年形象大使, 北京大学</li>
              <li>2015, 十佳毕业论文, 北京大学信息科学技术学院</li>
              <li>2015, Top 10%论文奖, IEEE MMSP</li>
            </ul>

            <h2 id="services">学术服务</h2>
            <b>学术机构任职</b>
            <ul>
              <li>CSIG 中国图象图形学学会, 多媒体专委会委员</li>
              <li>VALSE 视觉与学习青年学者研讨会, 执行领域主席委员会EACC</li>
            </ul>            
            <b>领域主席 AC</b>
            <ul>
              <li>ACM MM 2024</li>
              <li>BMVC 2023/2024</li>
            </ul>
              <b>资深程序委员 SPC</b>:
              <ul>
                <li>AAAI 2022/23/24</li>
              </ul>
              <b>程序委员/审稿人 PC/Reviwer</b>:
              <ul>
                <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                <li>IEEE Transactions on Visualization and Computer Graphics (TVCG)</li>
                <li>International Journal of Computer Vision (IJCV)</li>
                <li>IEEE Transactions on Image Processing (TIP)</li>
                <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                <li>IEEE Transactions on Multimedia (TMM)</li>
                <li>CVPR 2019/20/21/22/23/24</li>
                <li>ICCV 2019/21/23</li>
                <li>ECCV 2020/22/24</li>
                <li>SIGGRAPH 2022/23/24, SIGGRAPH Asia 2023</li>
                <li>ICLR 2022/23/25</li>
                <li>AAAI 2020/21</li>
                <li>NeurIPS 2022/23</li>               
              </ul>


              <!--Teaching-->
              <h2 id="teaching" style="margin-bottom: 25px;">教学工作</h2>
              <ul>
                <li>04831300 图像处理 (本科生课程) 2024 秋季</li> 
                <li>04831750 程序设计实习 (本科生课程) 2025 春季</li>          
              </ul>  
          </div>
        </div>
      </div>
    </div>



    <!-- Footer -->
    <footer class="container" >
      <br><hr>
      <!--<div class="row" style="text-align: center">
        © modified from 2022-2023 Zudi Lin's website
        Zhexin Liang
      </div>-->
     
      <div class="footer_social" style= "text-align: center; margin-left: 275px;">
        <span style="display:inline; font-size: 2em; margin-right: 7px; color: #4a4a4a;">杨帅</span>
        
        <a href="https://github.com/williamyang1991" target="_blank">
          <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
        </a>
        <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
          <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <a href="mailto:williamyang@pku.edu.cn" target="_blank">
          <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <div class="footer_social" style= "display:inline; float:right;  font-size: 2em;">
          © modified from Zudi Lin's website
        </div>
      
 
    </footer>
</section>

  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
