<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>杨帅</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/misc/yangshuai2.jpg">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%;
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="margin-top: 6px;">
              <img src="images/misc/yangshuai2.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">杨  帅</h2>
              <p>
                <b>王选计算机研究所</b><br/> 
                北京大学<br/> 
              </p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/williamyang1991" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:williamyang@pku.edu.cn" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div>
            <!-- slogon -->
          
            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <ul class="menu-list">
                <li><a href="#intro">个人简介</a></li>
                <!--<li><a href="#experiences">学术经历</a></li>-->
                <li><a href="#project">科研项目</a></li>
                <li><a href="#publications">发表成果</a></li>
                <li><a href="#awards">奖项荣誉</a></li>
                <li><a href="#services">学术服务</a></li>
                <!--<li><a href="#teaching">教学工作</a></li>-->
              </ul>
              <p style="margin-top: .4em;">
                <a href="https://williamyang1991.github.io/" style="color:#4a4a4a; padding: .5em .75em;"><b>English</b> ⤴️</a>
              </p>
            </div>
          </div>

          

        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="intro">个人简介</h2>
            <p style="text-align: justify;">
              <b>杨帅</b>, 北京大学王选计算机技术研究所助理教授、博导、北京大学博雅青年学者、未名青年学者、国家级青年人才计划获得者. 
              分别在2015年和2020年获得北京大学的学士学位和博士学位, 
              2020年至2024年在新加坡南洋理工大学先后任博士后和研究助理教授. 
              获得了IEEE ICME 2020的最佳论文奖和IEEE MMSP 2015的Top10%论文奖. 
              获得了2020年中国图象图形学学会优秀博士学位论文奖和北京大学优秀博士学位论文奖. 
              担任ACM MM和BMVC的领域主席. 
            </p>

            <p>
              主要研究领域为智能媒体计算和计算机视觉, 专注图像风格化和图像编辑. 
            </p>
            

            <!--Experience-->
            <h2 id="experiences" style="margin-bottom: 25px;">科研经历</h2>
            <ul>
              <li>2024.03&nbsp;&nbsp;&nbsp;&nbsp;至&nbsp;&nbsp;&nbsp;今: <b>助理教授</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学</li> 
              <li>2023.03-2024.02: <b>研究助理教授</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@南洋理工大学</li> 
              <li>2020.10-2023.03: <b>博士后</b> | <a href="https://www.mmlab-ntu.com/">MMLab</a>@南洋理工大学 | 导师 Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a></li>    
              <li>2018.09-2019.09: <b>访问学者</b> | <a href="https://vita-group.github.io/index.html">VITA</a>@德州农工大学 | 导师 Prof. <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang" target="_blank">Atlas Wang</a></li> 
              <li>2017.03-2017.08: <b>访问学生</b> | <a href="https://www.eecs.yorku.ca/~genec/group.html">GSIP</a>@日本国立情报学研究所 | 导师 Prof. <a href="https://www.eecs.yorku.ca/~genec/index.html" target="_blank">Gene Cheung</a></li>                       
              <li>2015.09-2020.07: <b>博士</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学 | 导师 <a href="https://www.icst.pku.edu.cn/english/people/gg/1297382.htm" target="_blank">郭宗明</a> 研究员</li>
              <li>2010.09-2015.07: <b>学士</b> | <a href="http://39.96.165.147/struct.html">STRUCT</a>@北京大学 | 导师 <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html" target="_blank">刘家瑛</a> 副教授</li>         
            </ul>  


            <h2 id="news" style="margin-bottom: 25px;">最新动态</h2>
            <ul>
              <li>2025.06 😆 3 篇论文被 ICCV 2025 接收! </li>
              <li>2025.02 😆 3 篇论文被 CVPR 2025 接收! </li>
              <li>2024.07 加入 CSIG 中国图象图形学学会 多媒体专委会</li> 
              <li>2024.07 参加 ICME Workshop on AIArt 作 Keynote 报告: AIGC for Human Artistic Rendering</li> 
              <li>2024.07 😆 2 篇论文被 ECCV 2024 接收! </li>
              <li>2024.05 参会 ISCAS 作 Tutorial: AIGC for Image and Video Generation</li>  
              <li>2024.03 加入 北京大学 王选计算机技术研究所 担任助理教授 </li>                       
              <details>
              <summary><li style="margin-top: 5px; margin-bottom: 5px;">展开更多</li></summary>
                <li>2024.12 参会 智能传媒技术发展论坛 作学术报告: 智能视觉艺术创作</li>
                <li>2024.11 参会 黄大年茶思屋 多媒体领域青年学者论坛 作学术报告: 人像智能艺术渲染</li>                
                <li>2024.09 欢迎巴西圣保罗大学 Roberto M. Cesar-Jr 教授来访!</li> 
                <li>2024.08 参加 APSIPA panel discussion</li>   
                <li>2024.06 参加 VALSE Webinar 作学术报告: 人像智能艺术设计</li>
                <li>2024.02 😆 2 篇论文被 CVPR 2024 接收! </li>
                <li>2023.07 😆 4 篇论文被 ICCV 2023 接收! </li>    
                <li>2023.03 晋升 南洋理工大学S-Lab 研究助理教授 (RAP) </li>
              </details>
            </ul> 

  
            <!--Project-->
            <h2 id="project" style="margin-bottom: 25px;">科研项目</h2>
            
            <ul>
              <li>2025-2028, 主持, 国家自然科学基金面上项目: 视觉内容的智能可控生成编辑研究, No.62471009</li> 
              <li>2024-2025, 主持, CCF-腾讯犀牛鸟科研基金项目: 图像视频的智能可控生成与编辑, CCF-Tencent RAGR20240118</li> 
              <li>2025-2027, 参与, 国家重点研发计划: 复杂动态场景高保真实时三维重建, 2024YFB2809101</li> 
              <li>2023-2025, 合作研究员, 商汤高校合作项目: Artistic Neural Radiance Fields, HASI-006</li>    
              <li>2021-2023, 合作研究员, 新加坡教育部Tier-1基金: Human-Centric Visual Manipulation via Interactive Dialog, MoE Tier-1 RG13/21</li>         
            </ul>                                                                                


            <!--Publications-->
            <h2 id="publications">
              发表成果
            </h2>
            <p>完整列表请移步 <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">Google Scholar</a>; 论文相关资源请移步 <a href="https://williamyang1991.github.io/publication.html" target="_blank">Publication</a> </p> 
            <!--List of publications-->
            <b>精选期刊论文</b>
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.45, No.10, pp.11869-11993, Oct. 2023.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, and Jiaying Liu. "Shape-Matching GAN++: Scale Controllable Dynamic Artistic Text Style Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.44, No.7, pp.3807-3820, July 2022.</li> 
              <li><b>Shuai Yang</b>†, Wenjing Wang†, and Jiaying Liu. "TE141K: Artistic Text Benchmark for Text Effect Transfer", IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Vol.43, pp.3709-3723, Oct. 2021. (†Equal contribution)</li> 
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "VToonify: Controllable High-Resolution Portrait Video Style Transfer", ACM Transactions on Graphics (<b>SIGGRAPH Asia - TOG</b>), Vol.41, No.6, pp.1-15, 2022.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Controllable Sketch-to-Image Translation for Robust Face Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.30, pp.8797-8810, 2021.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Text-Based Binary Image Stylization and Synthesis", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.952-964, Feb. 2019. </li>
              <li><b>Shuai Yang</b>, Yueyu Hu, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: Scalable Face Image Coding", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.23, pp.2957-2971, Sep. 2021. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Text Effects Transfer via Distribution-Aware Texture Synthesis", Computer Vision and Image Understanding (<b>CVIU</b>), Vol.174, pp.43-56, Sep. 2018.</li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Yuming Fang, and Zongming Guo. "Joint-Feature Guided Depth Map Super-Resolution with Face Priors", IEEE Transactions on Cybernetics (<b>TCYB</b>), Vol.48, No.1, pp.399-411, Jan. 2018.</li>
              <!--<li>Yuhang Bai, Zichuan Huang, Wenshuo Gao, <b>Shuai Yang</b>*, Jiaying Liu. "Intelligent Artistic Typography: A Comprehensive Review of Artistic Text Design and Generation", APSIPA Transactions on Signal and Information Processing (ATSIP), Vol.13, No.1, pp.1-39, 2024.</li>-->
              <li> Yushi Lan, Xuyi Meng, <b>Shuai Yang</b>, Chen Change Loy, and Bo Dai. "E3DGE: Self-supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion", International Journal of Computer Vision  (<b>IJCV</b>), Jun. 2025.</li>	
              <li>Wendong Mao, <b>Shuai Yang</b>, Huihong Shi, Jiaying Liu, Zhongfeng Wang. "Intelligent Typography: Artistic Text Style Transfer for Complex Texture and Structure", IEEE Transactions on Multimedia (<b>TMM</b>), Vol. 25, pp.6485-6498, Nov. 2023.</li>
              <li>Yuming Jiang, <b>Shuai Yang</b>, Haonan Qiu, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Human: Text-Driven Controllable Human Image Generation", ACM Transactions on Graphics (<b>SIGGRAPH - TOG</b>), Vol.41, No.4, pp.1-11, 2022.</li>
              <li>Xinhao Wang, Wenjing Wang, <b>Shuai Yang</b>, and Jiaying Liu. "CLAST: Contrastive Learning for Arbitrary Style Transfer", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.31, pp.6761-6772, 2022.</li>
              <li>Wenjing Wang, <b>Shuai Yang</b>, Jizheng Xu, and Jiaying Liu. "Consistent Video Style Transfer via Relaxation and Regularization", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.29, pp.8680-8695, 2020.</li>
              <li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Scale-Free Single Image Deraining via Visibility-Enhanced Recurrent Wavelet Learning", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.6, pp.2948-2961, Jun. 2019. </li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, and Zongming Guo. "D3R-Net: Dynamic Routing Residue Recurrent Network for Video Rain Removal", IEEE Transactions on Image Processing (<b>TIP</b>), Vol.28, No.2, pp.699-712, Feb. 2019. </li>
              <!--<li>Xinhao Wang, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Artistic Text Style Transfer", IEEE Signal Processing Magazine (SPM), Vol.39, pp.10-17, Nov. 2022.</li>-->
              <li>Jiaying Liu, <b>Shuai Yang</b>, Yuming Fang, Zongming Guo. "Structure-Guided Image Inpainting Using Homography Transformation", IEEE Transactions on Multimedia (<b>TMM</b>), Vol.20, No.12, pp.3252-3265, Dec. 2018.</li>             
            </ol>
            <b>精选会议论文</b>
            <ol class="custom-list">
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li><b>Shuai Yang</b>, Yifan Zhou, Ziwei Liu, and Chen Change Loy. "Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation", ACM SIGGRAPH Asia Conference Proceedings (<b>SIGGRAPH Asia</b>), 2023.</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces", International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Liming Jiang, Ziwei Liu, and Chen Change Loy. "Unsupervised Image-to-Image Translation with Generative Prior", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.</li></li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Jiaying Liu, and Zongming Guo. "Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches", European Conference on Computer Vision (<b>ECCV</b>), 2020.</li>
              <li><b>Shuai Yang</b>, Zhangyang Wang, Zhaowen Wang, Ning Xu, Jiaying Liu, Zongming Guo. "Controllable Artistic Text Style Transfer via Shape-Matching GAN", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenjing Wang and Zongming Guo. "TET-GAN: Text Effects Transfer via Stylization and Destylization", AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2019. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Wenhan Yang, and Zongming Guo. "Context-Aware Unsupervised Text Stylization", ACM Multimedia (<b>ACM MM</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Zhouhui Lian, and Zongming Guo. "Awesome Typography: Statistics-Based Text Effects Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017. </li>
              <!--<li><b>Shuai Yang</b>, Gene Cheung, Jiaying Liu, and Zongming Guo. "Soft Decoding of Light Field Images Using POCS and Fast Graph Spectral Filters", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2018. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sifeng Xia, and Zongming Guo. "1+N Fusion: Cascaded Self-Portrait Enhancement", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2017. </li>
              <li><b>Shuai Yang</b>, Jiaying Liu, Sijie Song, Mading Li and Zongming Guo. "Structure-Guided Image Completion via Regularity Statistics", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2016. </li>
              <li><b>Shuai Yang</b>, Sijie Song, Qikun Guo, Xiaoqing Lu and Jiaying Liu. "Facial Depth Map Enhancement via Neighbor Embedding", International Conference on Pattern Recognition (ICPR), 2016. </li>
              <li>Xicheng Lan, Wenshuo Gao, Luyao Zhang, Jiaying Liu, and <b>Shuai Yang</b>*. "Splice, Focus and Relife: High-Resolution Periodic Pattern Generation", IEEE International Symposium on Circuits and Systems (<b>ISCAS</b>), 2025.</li>
              <li>Zichuan Huang, Yifan Li, <b>Shuai Yang</b>*, and Jiaying Liu. "CoolColor: Text-guided COherent OLd film COLORization", ACM Multimedia Asia (ACM MM Asia), 2024.</li>-->
              <li>Wenshuo Gao, Xicheng Lan, and <b>Shuai Yang*</b>. "AnyPortal: Zero-Shot Consistent Video Background Replacement", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Yuxin Jiang, Liming Jiang, <b>Shuai Yang</b>, Jia-Wei Liu, Ivor W. Tsang, and Mike Shou Zheng. "Balanced Image Stylization with Style Matching Score", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Wenqi Ouyang, Zeqi Xiao, Danni Yang, Yifan Zhou, <b>Shuai Yang</b>, Lei Yang, Jianlou Si, and Xingang Pan. "TokensGen: Harnessing Condensed Tokens for Long Video Generation", International Conference on Computer Vision (<b>ICCV</b>), 2025.</li>
              <li>Xiang Gao, <b>Shuai Yang</b>, Jiaying Liu. "PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures using Phase-Transferred Diffusion Model", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025.</li>
              <li>Yifan Zhou, Zeqi Xiao, <b>Shuai Yang</b>, Xingang Pan. "Alias-free Latent Diffusion Models: Improving Fractional Shift Equivariance of Diffusion Latent Space", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),2025.</li>
              <li>Yuhan Wang, Fangzhou Hong, <b>Shuai Yang</b>, Liming Jiang, Wayne Wu, Chen Change Loy. "MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025.</li>              
              <li>Zeqi Xiao, Wenqi Ouyang, Yifan Zhou, <b>Shuai Yang</b>, Lei Yang, Jianlou Si, Xingang Pan. "Trajectory Attention for Fine-grained Video Motion Control", International Conference on Learning Representations (<b>ICLR</b>), 2025.</li>
              <li>Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, <b>Shuai Yang</b>, Bo Dai, Xingang Pan, Chen Change Loy. "GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation", International Conference on Learning Representations (<b>ICLR</b>), 2025.</li>
              <li>Zeqi Xiao, Yifan Zhou, <b>Shuai Yang</b>, Xingang Pan. "Video Diffusion Models are Training-free Motion Interpreter and Controller", Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</li>
              <li>Yifan Li, Yuhang Bai, <b>Shuai Yang</b>, and Jiaying Liu. "COCO-LC: Colorfulness Controllable Language-based Colorization", ACM Multimedia (<b>ACM MM</b>), 2024.</li>
              <li>Yushi Lan, Fangzhou Hong, <b>Shuai Yang</b>, Shangchen Zhou, Xuyi Meng, Bo Dai, Xingang Pan, Chen Change Loy. "LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Nanxuan Zhao, Qing Liu, Krishna Kumar Singh, <b>Shuai Yang</b>, Chen Change Loy, Ziwei Liu. "GroupDiff: Diffusion-based Group Portrait Editing", European Conference on Computer Vision (<b>ECCV</b>), 2024.</li>
              <li>Yuming Jiang, Tianxing Wu, <b>Shuai Yang</b>, Chenyang Si, Dahua Lin, Yu Qiao, Chen Change Loy, Ziwei Liu. "VideoBooth: Diffusion-based Video Generation with Image Prompts", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.</li>
              <li>Yuming Jiang, <b>Shuai Yang</b>, Tong Liang Koh, Wayne Wu, Chen Change Loy, and Ziwei Liu. "Text2Performer: Text-Driven Human Video Generation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yuxin Jiang, Liming Jiang, <b>Shuai Yang</b>, and Chen Change Loy. "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Junzhe Zhang, Yushi Lan, <b>Shuai Yang</b>, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, and Chen Change Loy. "DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields", IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023.</li>
              <li>Yushi Lan, Xuyi Meng, <b>Shuai Yang</b>, Chen Change Loy, and Bo Dai. "E3DGE: Self-supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.</li>
              <li>Hao Liang, <b>Shuai Yang</b>, Wenjing Wang and Jiaying Liu. "Instance-Aware Coherent Video Style Transfer for Chinese Ink Wash Painting", International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2021.</li>
              <li>Qiyu Dai, <b>Shuai Yang</b>, Wenjing Wang, Wei Xiang and Jiaying Liu. "Edit Like A Designer: Modeling Design Workflows for Unaligned Fashion Editing", ACM Multimedia (<b>ACM MM</b>), 2021.</li>
              <li>Yu Han, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "From Design Draft to Real Attire: Unaligned Fashion Image Translation", ACM Multimedia (<b>ACM MM</b>), 2020.</li>
              <li>Yueyu Hu, <b>Shuai Yang</b>, Wenhan Yang, Ling-Yu Duan, and Jiaying Liu. "Towards Coding for Human and Machine Vision: A Scalable Image Coding Approach", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020. (<b>Best Paper Award</b>)</li>
              <!--<li>Keqiang Yan, <b>Shuai Yang</b>, Wenjing Wang, and Jiaying Liu. "Multitask Attentive Network for Text Effects Quality Assessment", IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2020.</li>-->
              <li>Wenjing Wang, Jiaying Liu, <b>Shuai Yang</b>, and Zongming Guo. "Typography with Decor: Intelligent Text Style Transfer", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.</li>
              <li>Jiaying Liu, Wenhan Yang, <b>Shuai Yang</b>, Zongming Guo. "Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos", IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018.	</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Sifeng Xia and Zongming Guo. "Hierarchical Oil Painting Stylization with Limited Reference via Sparse Representation", IEEE International Workshop on Multimedia Signal Processing (<b>MMSP</b>), 2015. (<b>Top 10% Paper Awards</b>)</li>
              <!--<li>Wenhan Yang, Jiaying Liu, <b>Shuai Yang</b>, Zongming Guo. "Novel Autoregressive Model Based on Adaptive Window-Extension and Patch-Geodesic Distance for Image Interpolation", IEEE International Conference on Acoustics, Speech, and Signal Processing (<b>ICASSP</b>), 2015.</li>
              <li>Saboya Yang, Jiaying Liu, Wenhan Yang and <b>Shuai Yang</b>. "Soft Segmentation-Guided Bipartite Graph Image Stylization ", IEEE International Conference on Image Processing (<b>ICIP</b>), 2017.</li>
              <li>Saboya Yang, Jiaying Liu, <b>Shuai Yang</b>, Wenhan Yang and Zongming Guo. "Joint-Domain Unsupervised Stylization for Portraits", IEEE International Symposium on Circuits and Systems (<b>ISCAS</b>), 2017.</li>
              <li>Sifeng Xia, <b>Shuai Yang</b>, Jiaying Liu, and Zongming Guo. "Novel Self-Portrait Enhancement via Multi-Photo Fusing", Asia Pacific Signal and Information Processing Association (APSIPA), 2016.</li>-->              
            </ol>
            <b>书籍教材</b>:
            <ol class="custom-list">
                <li><b>Shuai Yang</b>, Zhengbo Xu, Wenjing Wang, Jiaying Liu. "Artistic Text Style Transfer". ISBN: 978-1003406273, Artificial Intelligence for Art Creation and Understanding, CRC Press. 2024-08-29</li>
                <li>Ziwei Liu, <b>Shuai Yang</b>, Yuming Jiang, Ziqi Huang. "Generative Networks". ISBN: 978-3-031-43566-9, Handbook of Face Recognition. Springer, Cham. 2023-12-30</li>
                <li>刘家瑛, <b>杨帅</b>, 杨文瀚, 段凌宇, 《计算机视觉理论与实践》, ISBN: 9787040574463, 2022-10-01 (“智能基座”优秀教材)</li>              
            </ol>
                     
            <b>授权专利</b>:
            <ol class="custom-list">
              <li>刘家瑛, <b>杨帅</b>, 杨文瀚, 郭宗明, 一种图文结合的海报生成方法和系统, ZL201811068309.9, 2023年05月02日. </li>
              <li>刘家瑛, 胡煜章, 汪文靖, <b>杨帅</b>, 郭宗明, 一种针对特效字的智能字效迁移方法, ZL201910440039.8, 2022年07月26日. </li>
              <li>刘家瑛, 胡越予, <b>杨帅</b>, 王德昭, 郭宗明, 一种可扩展人机协同图像编码方法及编码系统, ZL2019114155617, 2022年01月06日. </li>
              <li><b>杨帅</b>, 刘家瑛, 宋思捷, 郭宗明, 深度图增强方法和深度图增强装置, ZL201611093936.9, 2021年04月09日. </li>
              <li>刘家瑛, <b>杨帅</b>, 汪文靖, 郭宗明, 一种联合风格化和去风格化的艺术字编辑方法和系统, ZL201811487971.8, 2021年01月19日. </li>
              <li>刘家瑛, 杨文瀚, 魏晨, <b>杨帅</b>, 郭宗明, 视频去雨的方法、装置、设备及计算机可读存储介质, ZL201810541578.6, 2020年12月04日. </li>
              <li>刘家瑛, <b>杨帅</b>, 连宙辉, 郭宗明, 一种基于多通道的艺术字生成方法及系统, ZL201810078035.5, 2020年11月03日. </li>
              <li><b>杨帅</b>, 刘家瑛, 夏思烽, 郭宗明, 图像拼接方法及装置, ZL201710134639.2, 2020年10月16日. </li>
              <li><b>杨帅</b>, 夏思烽, 刘家瑛, 郭宗明, 多张图片融合的方法及装置, ZL201710021329.X, 2020年10月16日. </li>
              <li>杨文瀚, 刘家瑛, <b>杨帅</b>, 郭宗明, 一种基于网络图像块检索的图像重建方法及系统, ZL2015100633384.5, 2019年08月30日. </li>
              <li>白蔚, 刘家瑛, <b>杨帅</b>, 郭宗明, 一种图像风格化重建方法及装置, ZL201510379988.1, 2019年05月07日. </li>
              <li>杨撒博雅, 刘家瑛, <b>杨帅</b>, 郭宗明, 图像风格化重建的方法和装置, ZL201510045335.X, 2019年05月14日. </li>
              <li><b>杨帅</b>, 刘家瑛, 李马丁, 李翘楚, 郭宗明, 多边形检测方法和多边形检测装置, ZL201410193194.1, 2019年02月26日. </li>
              <li>刘家瑛, 李翘楚, 李马丁, <b>杨帅</b>, 郭宗明, 图像处理装置和图像处理方法, ZL 201410200267.5, 2018年04月17日. </li>
            </ol> 
            <b>申请专利</b>:
            <ol class="custom-list">
              <li><b>杨帅</b>, 兰晰程, 高文硕, 张璐瑶, 刘家瑛, 一种具有周期性的清晰图像生成方法, 202411823199.8, 2024年12月11日.</li>
              <li><b>杨帅</b>, 高文硕, 兰晰程, 张璐瑶, 基于隐式神经表示和文本到视频扩散模型的矢量图形动画生成方法及系统, 202411799939.9, 2024年12月09日.</li> 
              <li>刘家瑛, 李一凡, <b>杨帅</b>, 一种颜色可控的文本引导灰色图着色方法及系统, 2024107362011, 2024年06月07日.</li>
              <li>姜瑜铭, <b>杨帅</b>，许统量，吴文岩，吕健勤，刘子纬，视频生成及模型训练方法、装置、设备、存储介质, 202311175888.8, 2023年09月11日.</li>
              <li><b>杨帅</b>, 蒋李鸣, 刘子纬, 吕健勤, 陶晴怡, 图像处理方法、装置、设备及存储介质, 202310355783.4, 2023年04月04日.</li>
              <li><b>杨帅</b>, 蒋李鸣, 刘子纬, 吕健勤, 张俊哲, 模型训练及图像处理方法、装置、设备及存储介质, 202310189704.7, 2023年02月08日.</li>           
              <li><b>杨帅</b>, 蒋李鸣, 刘子纬, 吕健勤, 陶晴怡, 图像处理方法及装置、终端、存储介质, 202210430944.7, 2022年04月22日.</li>
              <li><b>杨帅</b>, 蒋李鸣, 刘子纬, 吕健勤, 钱晨, 图像转换方法、装置、设备及存储介质, 202210179321.7, 2022年02月25日.</li>
              <li>刘家瑛, 梁浩, 汪文靖, <b>杨帅</b>, 郭宗明, 一种基于实例分割和参考帧的水墨视频生成方法及装置, 202110571615X, 2021年05月25日.</li>
              <li>刘家瑛, 王欣灏, 汪文靖, <b>杨帅</b>, 郭宗明, 一种基于对比学习的任意风格迁移方法及系统, 202110528861.7, 2021年05月14日.</li>
            </ol> 

            <!--Awards-->
            <h2 id="awards">奖项荣誉</h2>
            <ul>
              <li>2024, 王选青年教师奖, 北京大学王选计算机研究所</li>
              <li>2024, 北京市科学技术发明奖 二等奖</li> 
              <li>2023, 杰出审稿人, IEEE/CVF CVPR</li>        
              <li>2022, 杰出审稿人, ECCV</li>      
              <li>2020, 最佳论文奖, IEEE ICME</li>         
              <li>2020, 优秀博士学位论文奖, 中国图象图形学学会</li>
              <li>2020, 优秀博士学位论文奖, 北京大学</li>
              <li>2019, 学术十杰, 北京大学信息科学技术学院</li>
              <li>2018, 网络新青年形象大使, 北京大学</li>
              <li>2015, 十佳毕业论文, 北京大学信息科学技术学院</li>
              <li>2015, Top 10% 论文奖, IEEE MMSP</li>
            </ul>

            <h2 id="services">学术服务</h2>
            <b>学术机构任职</b>
            <ul>
              <li>CSIG 中国图象图形学学会, 多媒体专委会委员</li>
              <li>VALSE 视觉与学习青年学者研讨会, 执行领域主席委员会 EACC</li>
            </ul>            
            <b>领域主席 AC</b>
            <ul>
              <li>NeurIPS 2025</li>
              <li>ACM MM 2024/2025</li>
              <li>BMVC 2023/2024/2025</li>
            </ul>
              <b>资深程序委员 SPC</b>:
              <ul>
                <li>AAAI 2022/23/24</li>
              </ul>
              <b>程序委员/审稿人 PC/Reviwer</b>:
              <ul>
                <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
                <li>IEEE Transactions on Visualization and Computer Graphics (TVCG)</li>
                <li>International Journal of Computer Vision (IJCV)</li>
                <li>IEEE Transactions on Image Processing (TIP)</li>
                <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
                <li>IEEE Transactions on Multimedia (TMM)</li>
                <li>CVPR 2019/20/21/22/23/24</li>
                <li>ICCV 2019/21/23</li>
                <li>ECCV 2020/22/24</li>
                <li>SIGGRAPH 2022/23/24, SIGGRAPH Asia 2023</li>
                <li>ICLR 2022/23/25</li>
                <li>AAAI 2020/21</li>
                <li>NeurIPS 2022/23</li>               
              </ul>


              <!--Teaching-->
              <h2 id="teaching" style="margin-bottom: 25px;">教学工作</h2>
              <ul>
                <li>04831300 图像处理 (本科生课程) 2024 秋季</li> 
                <li>04831750 程序设计实习 (本科生课程) 2025 春季</li>          
              </ul>  
          </div>
        </div>
      </div>
    </div>



    <!-- Footer -->
    <footer class="container" >
      <br><hr>
      <!--<div class="row" style="text-align: center">
        © modified from 2022-2023 Zudi Lin's website
        Zhexin Liang
      </div>-->
     
      <div class="footer_social" style= "text-align: center; margin-left: 275px;">
        <span style="display:inline; font-size: 2em; margin-right: 7px; color: #4a4a4a;">杨帅</span>
        
        <a href="https://github.com/williamyang1991" target="_blank">
          <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
        </a>
        <a href="https://scholar.google.com/citations?user=_1UDYowAAAAJ" target="_blank">
          <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <a href="mailto:williamyang@pku.edu.cn" target="_blank">
          <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 6px"></span>
        </a>
        <div class="footer_social" style= "display:inline; float:right;  font-size: 2em;">
          © modified from Zudi Lin's website
        </div>
      
 
    </footer>
</section>

  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
